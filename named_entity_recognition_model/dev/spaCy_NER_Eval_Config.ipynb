{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy_NER_Eval_Config.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dYR2u9U0_JLB",
        "rZDk28NRC_s8"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQUUODx7h4v"
      },
      "source": [
        "# NER Evaluation of Augmented data\n",
        "\n",
        "* This evaluation is done in Google Colab because of:\n",
        "    * Enormous dataset size\n",
        "    * Transformer based architecture involving GPU usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYR2u9U0_JLB"
      },
      "source": [
        "## Install spaCy and download English model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRBO4JulnpP7"
      },
      "source": [
        "# !pip install cupy-cuda112\n",
        "!pip install spacy==3.0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaJC5o7XpHOs"
      },
      "source": [
        "# Download spacy small model\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JtYDT_Dx7S"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBp28TAJmhB"
      },
      "source": [
        "## Install torch\n",
        "\n",
        "* Install torch specifc to the Google Colab's CUDA version\n",
        "* CUDA version 11.1 works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LAGZmbvE0VQ"
      },
      "source": [
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WzjtepqIlx2"
      },
      "source": [
        "## Extract Project files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd4cI8yUIscq"
      },
      "source": [
        "!unzip /content/project.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZDk28NRC_s8"
      },
      "source": [
        "## Pre-process and save to json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNJ16vJ5Xov"
      },
      "source": [
        "### Extract the augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wph-DdQFKPnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39900b32-673c-4124-e0ca-6d0c7e6cf7ed"
      },
      "source": [
        "!unzip /content/augmented_dataset_2021-06-21.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/augmented_dataset_2021-06-21.zip\n",
            "   creating: augmented_dataset_2021-06-21/\n",
            "  inflating: augmented_dataset_2021-06-21/keyword_ids.csv  \n",
            "  inflating: augmented_dataset_2021-06-21/pattern_ids.csv  \n",
            "  inflating: augmented_dataset_2021-06-21/test_content.csv  \n",
            "  inflating: augmented_dataset_2021-06-21/test_context.csv  \n",
            "  inflating: augmented_dataset_2021-06-21/test_unseen.csv  \n",
            "  inflating: augmented_dataset_2021-06-21/train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qCBw9tx5f9R"
      },
      "source": [
        "### Loader function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDjtHcwhDMYD"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import numpy\n",
        "from numpy.core.defchararray import find\n",
        "\n",
        "TRAIN_DATA_PATH = \"./augmented_dataset_2021-06-21/train.csv\"\n",
        "TEST_CONTENT_DATA_PATH = \"./augmented_dataset_2021-06-21/test_content.csv\"\n",
        "TEST_CONTEXT_DATA_PATH = \"./augmented_dataset_2021-06-21/test_context.csv\"\n",
        "TEST_UNSEEN = \"./augmented_dataset_2021-06-21/test_unseen.csv\"\n",
        "\n",
        "def load_cleaned_data(data_path, train_data_only=None, train_data_pd=None):\n",
        "    \"\"\"\n",
        "    Go through every sentence's all word-tag pair (except \"NONE\")\n",
        "    and calculate the start and end index.\n",
        "    After getting the (start, end) pair, check if this pair was already calculated\n",
        "    (i.e., either the start_index, OR end_index, OR both are matching with the ones in list),\n",
        "    and if so, discard the pair and continue calculating again, skipping over the one discarded.\n",
        "    :return: DATA\n",
        "    \"\"\"\n",
        "    if train_data_only is None:\n",
        "        col_names = ['text', 'entities']\n",
        "\n",
        "        data = pd.read_csv(data_path, names=col_names, usecols=[0, 1])\n",
        "        entity_list = data.entities.to_list()\n",
        "\n",
        "    else:\n",
        "        # Incoming `train_data_only` is itself a pandas,\n",
        "        # so just process it.\n",
        "        entity_list = train_data_only\n",
        "        data = train_data_pd\n",
        "\n",
        "    DATA = []\n",
        "\n",
        "    for index, ent in enumerate(entity_list):\n",
        "        if ent == \"tokens\":\n",
        "            continue\n",
        "\n",
        "        ent = ent.split(\"), (\")\n",
        "        ent[0] = re.sub(\"[([]\", \"\", ent[0])\n",
        "        ent[-1] = re.sub(\"[)]]\", \"\", ent[-1])\n",
        "\n",
        "        # Initialize index list, to store pairs of (start, end) indices\n",
        "        indices_list = [(-1, -1), (-1, -1)]\n",
        "\n",
        "        tokens_list = []\n",
        "        spans_list = []\n",
        "\n",
        "        start_index = 0\n",
        "        end_index = 0\n",
        "\n",
        "        # Analyze current \"split_sentences\"'s all word-pairs\n",
        "        for index_ent, word_pair in enumerate(ent):\n",
        "            word_pair_list = []\n",
        "            \n",
        "            # Split the word and its pair\n",
        "            word_pair_list = word_pair.split(\"'\")[1::2]\n",
        "\n",
        "            # Remove any leading or beginning blank space\n",
        "            word_pair_list[0] = word_pair_list[0].strip()\n",
        "\n",
        "            start_index = find(data['text'][index].lower(), word_pair_list[0]).astype(numpy.int64)\n",
        "            start_index = int(start_index + 0)\n",
        "            end_index = int(start_index + len(word_pair_list[0]))\n",
        "\n",
        "            # Incase word not found in the sentence\n",
        "            if start_index == -1:\n",
        "                print(\"\\n-1 error\")\n",
        "                print(\"Couldn't find:\")\n",
        "                print(word_pair_list[0])\n",
        "                print(\"in:\")\n",
        "                print(data['text'][index])\n",
        "                break\n",
        "\n",
        "            both_present = lambda: (start_index, end_index) in indices_list\n",
        "            start_present = lambda: start_index in [i[0] for i in indices_list]\n",
        "            end_present = lambda: end_index in [i[1] for i in indices_list]\n",
        "            left_blank = lambda: data['text'][index][start_index - 1] != \" \"\n",
        "\n",
        "            def right_blank():\n",
        "                # return true if there is no blank space after the end_index,\n",
        "                # as long as end_index is not at the end of the sentence\n",
        "                if len(data['text'][index].lower()) != end_index:\n",
        "                    return data['text'][index][end_index] != \" \"\n",
        "            \n",
        "            # Check if this start_index and/or end_index is already in the list:\n",
        "            # (To prevent overlapping with already tagged words)\n",
        "            flag = 0\n",
        "            while True:\n",
        "                if (start_index == -1 or end_index == -1):\n",
        "                    flag = 1\n",
        "                    break\n",
        "                if (both_present()) or (start_present()) or (end_present()) or (left_blank()) or (right_blank()):\n",
        "                \n",
        "                    start_index = find(data['text'][index].lower(), word_pair_list[0],\n",
        "                                        start=end_index + 1).astype(numpy.int64)\n",
        "                    start_index = int(start_index + 0)\n",
        "                    end_index = int(start_index + len(word_pair_list[0]))\n",
        "\n",
        "                else:\n",
        "                    indices_list.append((start_index, end_index))\n",
        "                    break\n",
        "            \n",
        "            if (flag == 1):\n",
        "                # Don't bother checking rest of the current sentence\n",
        "                break\n",
        "            \n",
        "            # Add ALL the words and their positions to a \"tokens\" list\n",
        "            tokens_list.append({\"text\": word_pair_list[0], \"start\": start_index, \"end\": end_index})\n",
        "\n",
        "            # Add the specially tagged words to a \"spans\" list\n",
        "            if word_pair_list[1] != \"NONE\":\n",
        "                spans_list.append({\"start\": start_index, \"end\": end_index, \"label\": word_pair_list[1]})\n",
        "\n",
        "        DATA.append({\"text\": data['text'][index].lower(), \"tokens\": tokens_list, \"spans\": spans_list, \"answer\": \"accept\"})\n",
        "        \n",
        "    return DATA\n",
        "\n",
        "\n",
        "# TRAIN_DATA = load_cleaned_data(TRAIN_DATA_PATH)\n",
        "# TEST_CONTENT = load_cleaned_data(TEST_CONTENT_DATA_PATH)\n",
        "# TEST_CONTEXT = load_cleaned_data(TEST_CONTEXT_DATA_PATH)\n",
        "# UNSEEN_DATA = load_cleaned_data(TEST_UNSEEN)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-W4UdARgRf"
      },
      "source": [
        "### Load and save `TRAIN_DATA` in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uePVdIfvRfn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5474e8-2f94-4e5e-9fb6-52342d1a99ed"
      },
      "source": [
        "from pandas import DataFrame\n",
        "from spacy.util import minibatch\n",
        "import json\n",
        "\n",
        "# Create assets directory if it doesn't already exist\n",
        "if not os.path.exists(\"assets\"):\n",
        "    os.makedirs(\"assets\")\n",
        "\n",
        "# Read the CSV file as Pandas df\n",
        "col_names = ['text', 'entities']\n",
        "data = pd.read_csv(TRAIN_DATA_PATH, names=col_names, usecols=[0, 1])\n",
        "\n",
        "# Shuffle the whole train data\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Calulate size of each of the `div` batches\n",
        "tot_size = len(data)\n",
        "div = 100\n",
        "num_groups = int(tot_size / div)\n",
        "print(f\"Size of each part: {num_groups}\\n\")\n",
        "\n",
        "# Divide the data into batches\n",
        "entity_list = data.entities.to_list()\n",
        "entity_batches = minibatch(entity_list, size=num_groups)\n",
        "data_batches = minibatch(data.values.tolist(), size=num_groups)\n",
        "\n",
        "# Process each batch one by one, and save its result in a seperate jsonl file\n",
        "for count, (entity_batch, data_batch) in enumerate(zip(entity_batches, data_batches)):\n",
        "    # if count < 10:\n",
        "    #     # Continue from the desired last batch\n",
        "    #     continue\n",
        "\n",
        "    # Convert the data_batches back to Pandas\n",
        "    data_df = DataFrame(data_batch, columns=col_names)\n",
        "\n",
        "    TRAIN_DATA = load_cleaned_data(data_path=TRAIN_DATA_PATH,\n",
        "                                   train_data_only=entity_batch,\n",
        "                                   train_data_pd=data_df)\n",
        "\n",
        "    with open(f\"assets/TRAIN_DATA{count}.jsonl\", 'w') as f:\n",
        "        for entry in TRAIN_DATA:\n",
        "            json.dump(entry, f)\n",
        "            f.write('\\n')\n",
        "\n",
        "    print(f\"Batch {count} procesed and saved.\")\n",
        "    \n",
        "    del TRAIN_DATA\n",
        "    del data_df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of each part: 19852\n",
            "\n",
            "Batch 0 procesed and saved.\n",
            "Batch 1 procesed and saved.\n",
            "Batch 2 procesed and saved.\n",
            "Batch 3 procesed and saved.\n",
            "Batch 4 procesed and saved.\n",
            "Batch 5 procesed and saved.\n",
            "Batch 6 procesed and saved.\n",
            "Batch 7 procesed and saved.\n",
            "Batch 8 procesed and saved.\n",
            "Batch 9 procesed and saved.\n",
            "Batch 10 procesed and saved.\n",
            "Batch 11 procesed and saved.\n",
            "Batch 12 procesed and saved.\n",
            "Batch 13 procesed and saved.\n",
            "Batch 14 procesed and saved.\n",
            "Batch 15 procesed and saved.\n",
            "Batch 16 procesed and saved.\n",
            "Batch 17 procesed and saved.\n",
            "Batch 18 procesed and saved.\n",
            "Batch 19 procesed and saved.\n",
            "Batch 20 procesed and saved.\n",
            "Batch 21 procesed and saved.\n",
            "Batch 22 procesed and saved.\n",
            "Batch 23 procesed and saved.\n",
            "Batch 24 procesed and saved.\n",
            "Batch 25 procesed and saved.\n",
            "Batch 26 procesed and saved.\n",
            "Batch 27 procesed and saved.\n",
            "Batch 28 procesed and saved.\n",
            "Batch 29 procesed and saved.\n",
            "Batch 30 procesed and saved.\n",
            "Batch 31 procesed and saved.\n",
            "Batch 32 procesed and saved.\n",
            "Batch 33 procesed and saved.\n",
            "Batch 34 procesed and saved.\n",
            "Batch 35 procesed and saved.\n",
            "Batch 36 procesed and saved.\n",
            "Batch 37 procesed and saved.\n",
            "Batch 38 procesed and saved.\n",
            "Batch 39 procesed and saved.\n",
            "Batch 40 procesed and saved.\n",
            "Batch 41 procesed and saved.\n",
            "Batch 42 procesed and saved.\n",
            "Batch 43 procesed and saved.\n",
            "Batch 44 procesed and saved.\n",
            "Batch 45 procesed and saved.\n",
            "Batch 46 procesed and saved.\n",
            "Batch 47 procesed and saved.\n",
            "Batch 48 procesed and saved.\n",
            "Batch 49 procesed and saved.\n",
            "Batch 50 procesed and saved.\n",
            "Batch 51 procesed and saved.\n",
            "Batch 52 procesed and saved.\n",
            "Batch 53 procesed and saved.\n",
            "Batch 54 procesed and saved.\n",
            "Batch 55 procesed and saved.\n",
            "Batch 56 procesed and saved.\n",
            "Batch 57 procesed and saved.\n",
            "Batch 58 procesed and saved.\n",
            "Batch 59 procesed and saved.\n",
            "Batch 60 procesed and saved.\n",
            "Batch 61 procesed and saved.\n",
            "Batch 62 procesed and saved.\n",
            "Batch 63 procesed and saved.\n",
            "Batch 64 procesed and saved.\n",
            "Batch 65 procesed and saved.\n",
            "Batch 66 procesed and saved.\n",
            "Batch 67 procesed and saved.\n",
            "Batch 68 procesed and saved.\n",
            "Batch 69 procesed and saved.\n",
            "Batch 70 procesed and saved.\n",
            "Batch 71 procesed and saved.\n",
            "Batch 72 procesed and saved.\n",
            "Batch 73 procesed and saved.\n",
            "Batch 74 procesed and saved.\n",
            "Batch 75 procesed and saved.\n",
            "Batch 76 procesed and saved.\n",
            "Batch 77 procesed and saved.\n",
            "Batch 78 procesed and saved.\n",
            "Batch 79 procesed and saved.\n",
            "Batch 80 procesed and saved.\n",
            "Batch 81 procesed and saved.\n",
            "Batch 82 procesed and saved.\n",
            "Batch 83 procesed and saved.\n",
            "Batch 84 procesed and saved.\n",
            "Batch 85 procesed and saved.\n",
            "Batch 86 procesed and saved.\n",
            "Batch 87 procesed and saved.\n",
            "Batch 88 procesed and saved.\n",
            "Batch 89 procesed and saved.\n",
            "Batch 90 procesed and saved.\n",
            "Batch 91 procesed and saved.\n",
            "Batch 92 procesed and saved.\n",
            "Batch 93 procesed and saved.\n",
            "Batch 94 procesed and saved.\n",
            "Batch 95 procesed and saved.\n",
            "Batch 96 procesed and saved.\n",
            "Batch 97 procesed and saved.\n",
            "Batch 98 procesed and saved.\n",
            "Batch 99 procesed and saved.\n",
            "Batch 100 procesed and saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ljvb--hbrcK"
      },
      "source": [
        "# Clear the assets folder\n",
        "! rm -r assets/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j15GJ2cBpxTO"
      },
      "source": [
        "# !!! Forcefully reset RAM by injecting a list of size 10^10 !!!\n",
        "[1]*10**10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaFqxUFg5jTv"
      },
      "source": [
        "### Save to JSONL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QamFbSfcXJT"
      },
      "source": [
        "import json\n",
        "\n",
        "if not os.path.exists(\"assets\"):\n",
        "        os.makedirs(\"assets\")\n",
        "\n",
        "# with open('assets/TRAIN_DATA.jsonl', 'w') as f:\n",
        "#     for entry in TRAIN_DATA:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/TEST_CONTENT.jsonl', 'w') as f:\n",
        "#     for entry in TEST_CONTENT:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/TEST_CONTEXT.jsonl', 'w') as f:\n",
        "#     for entry in TEST_CONTEXT:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/UNSEEN_DATA.jsonl', 'w') as f:\n",
        "#     for entry in UNSEEN_DATA:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jza6xEbE5ofN"
      },
      "source": [
        "### Zip the JSONL files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdsTfX-vqBd3"
      },
      "source": [
        "!zip -r /content/assets.zip /content/assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auxp_oSxUe2u"
      },
      "source": [
        "## Extract assets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQf0WHMtsGCy"
      },
      "source": [
        "!unzip /content/assets.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h9qaV3Blx5M"
      },
      "source": [
        "## Get the pre-processed JSONL dataset from Google Drive\n",
        "\n",
        "The below cell joins the jsonl files, but **does not format them properly**.  \n",
        "Probably not gonna be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0r0clYalvSQ"
      },
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "TRAIN = []\n",
        "\n",
        "for file_iter, f in enumerate(glob.glob(\"/content/gdrive/MyDrive/spacy_ner_data/augmented_dataset_2021-06-21/train_jsonl_files/shuffled/*.jsonl\")):\n",
        "    with open(f, \"rb\") as infile:\n",
        "        json_list = list(infile)\n",
        "        TRAIN.append(json_list)\n",
        "    print(f\"File {file_iter} appended.\")\n",
        "\n",
        "with open(\"merged_file_10th.jsonl\", \"w\") as outfile:\n",
        "     json.dump(TRAIN[0:198522], outfile)\n",
        "\n",
        "\n",
        "# read_files = glob.glob(\"/content/gdrive/MyDrive/spacy_ner_data/augmented_dataset_2021-06-21/train_jsonl_files/shuffled/*.jsonl\")\n",
        "# with open(\"merged_file.jsonl\", \"wb\") as outfile:\n",
        "#     outfile.write('[{}]'.format(\n",
        "#         b','.join([open(f, \"rb\").read() for f in read_files])))\n",
        "\n",
        "# for file_iter in range(100 + 1):\n",
        "#     BIG_DATA_PATH = f\"/content/gdrive/MyDrive/spacy_ner_data/augmented_dataset_2021-06-21/train_jsonl_files/shuffled/TRAIN_DATA{file_iter}.jsonl\"\n",
        "#     with open(BIG_DATA_PATH, 'r') as f:\n",
        "#         TRAIN.append(json.load(f))\n",
        "#     print(f\"File {file_iter} appended.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWnKdnlY24ee"
      },
      "source": [
        "del TRAIN"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOd_YEeE1r-b"
      },
      "source": [
        "!zip -r /merged_file_quarter.zip /content/merged_file_quarter.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jvWOqtpN9rT"
      },
      "source": [
        "## Convert the data to spaCy's binary format\n",
        "\n",
        "A shell script is made in order to run the preprocess Python script multiple times, iterating over all the 100 jsonl files of training dataset\n",
        "\n",
        "* The error logs generated by spaCy point to 11 sentences, each having 100 duplicates in the original train.csv file.\n",
        "* The actual reason of these spaCy errors are not duplicates but the inability of the preprocessing function (`load_cleaned_data`) to identiy tagged INTR and/or QLTY of very few specific sentences (To be fixed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1EhwYM5VpOE",
        "outputId": "0259213b-d8d2-4daa-8070-d2612164f09b"
      },
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p corpus\n",
        "\n",
        "drive_path=\"/content/gdrive/MyDrive/spacy_ner_data/augmented_dataset_2021-06-21/train_jsonl_files/shuffled/TRAIN_DATA\"\n",
        "jsonl_ext=\".jsonl\"\n",
        "\n",
        "saved_path=\"/content/corpus/TRAIN_DATA\"\n",
        "spacy_ext=\".spacy\"\n",
        "\n",
        "for file_iter in {0..100}\n",
        "do\n",
        "    jsonl_drive_path=\"$drive_path$file_iter$jsonl_ext\"\n",
        "    spacy_file_path=\"$saved_path$file_iter$spacy_ext\"\n",
        "\n",
        "    python scripts/preprocess.py \"$jsonl_drive_path\" \"$spacy_file_path\"\n",
        "done"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-30 15:04:49.834760: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA0.spacy\n",
            "2021-06-30 15:05:10.528826: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA1.spacy\n",
            "2021-06-30 15:05:28.217638: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA2.spacy\n",
            "2021-06-30 15:05:44.900325: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA3.spacy\n",
            "2021-06-30 15:06:01.431999: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA4.spacy\n",
            "2021-06-30 15:06:18.185448: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA5.spacy\n",
            "2021-06-30 15:06:35.064656: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA6.spacy\n",
            "2021-06-30 15:06:51.849436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description ambient bass guitar loop in the style of nba youngboy rod wave or lil durk please let me know if you have used this loop dm me on ig for part 2 vocal chops link in my profile' and words '[]'.\n",
            "2021-06-30 15:06:58.893094: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description man ableton looks wild so different i m used to fl electric piano roll therefore only electric piano for now xd' and words '[]'.\n",
            "2021-06-30 15:07:14.981583: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'what does good sax tone mean' and words '[]'.\n",
            "2021-06-30 15:07:30.100172: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'honestly i know what you re going through being able to truly hear the all the nuances to the timbre of acoustic instruments is extremely satisfying corey taylor stone sour covering wicked game in a live acoustic set the electric piano sound fantastic' and words '[]'.\n",
            "2021-06-30 15:07:35.941628: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA11.spacy\n",
            "2021-06-30 15:07:52.609612: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA12.spacy\n",
            "2021-06-30 15:08:09.303600: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19851 documents: TRAIN_DATA13.spacy\n",
            "2021-06-30 15:08:25.918349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA14.spacy\n",
            "2021-06-30 15:08:42.744058: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA15.spacy\n",
            "2021-06-30 15:08:59.504168: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA16.spacy\n",
            "2021-06-30 15:09:16.636074: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA17.spacy\n",
            "2021-06-30 15:09:33.485595: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description pop smoke lil baby da baby pianos darkcheck my profile for more loop kits and to connect with me via social media for exclusive and daily loop kits and etc' and words '[]'.\n",
            "2021-06-30 15:09:42.382120: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA19.spacy\n",
            "2021-06-30 15:09:59.030088: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA20.spacy\n",
            "2021-06-30 15:10:15.522658: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA21.spacy\n",
            "2021-06-30 15:10:32.004042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA22.spacy\n",
            "2021-06-30 15:10:48.506169: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA23.spacy\n",
            "2021-06-30 15:11:04.974696: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description melodic triplets drum drum loop in the style of roddy ricch lil baby gunna flipp dinero throw on some drum and loud 808s and u got a hit' and words '[]'.\n",
            "2021-06-30 15:11:19.811411: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA25.spacy\n",
            "2021-06-30 15:11:36.487522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA26.spacy\n",
            "2021-06-30 15:11:53.454043: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA27.spacy\n",
            "2021-06-30 15:12:09.831091: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA28.spacy\n",
            "2021-06-30 15:12:26.282599: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description omni-bells loopfeel free to share your work with me don t forget to check out my other loops by clicking on my profile picture' and words '[]'.\n",
            "2021-06-30 15:12:41.011670: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA30.spacy\n",
            "2021-06-30 15:12:57.754669: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA31.spacy\n",
            "2021-06-30 15:13:15.319338: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA32.spacy\n",
            "2021-06-30 15:13:31.856905: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA33.spacy\n",
            "2021-06-30 15:13:48.425729: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA34.spacy\n",
            "2021-06-30 15:14:04.937909: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA35.spacy\n",
            "2021-06-30 15:14:21.562547: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA36.spacy\n",
            "2021-06-30 15:14:38.120631: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA37.spacy\n",
            "2021-06-30 15:14:54.757155: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA38.spacy\n",
            "2021-06-30 15:15:14.982491: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA39.spacy\n",
            "2021-06-30 15:15:32.764155: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA40.spacy\n",
            "2021-06-30 15:15:49.441257: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA41.spacy\n",
            "2021-06-30 15:16:06.103424: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA42.spacy\n",
            "2021-06-30 15:16:22.561833: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA43.spacy\n",
            "2021-06-30 15:16:39.239471: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA44.spacy\n",
            "2021-06-30 15:16:56.025207: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA45.spacy\n",
            "2021-06-30 15:17:12.551051: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA46.spacy\n",
            "2021-06-30 15:17:29.815372: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA47.spacy\n",
            "2021-06-30 15:17:46.403522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA48.spacy\n",
            "2021-06-30 15:18:03.174645: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA49.spacy\n",
            "2021-06-30 15:18:20.016776: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description xpand nylon saxophone with several effects' and words '[]'.\n",
            "2021-06-30 15:18:25.398375: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA51.spacy\n",
            "2021-06-30 15:18:42.034313: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA52.spacy\n",
            "2021-06-30 15:18:58.598175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'out of these two even with the b2ds deficiencies in pianos middle registers of pianos as you mentioned with which do you enjoy listening to these instruments the most in your opinion for example what about the song you used time control or controlled by time where did it sound better to you i m considering buying the b2s or b2ds and can t decide but if the pianos pianos sound too much off with the b2ds that s a problem' and words '[]'.\n",
            "2021-06-30 15:19:14.742536: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA54.spacy\n",
            "2021-06-30 15:19:31.373146: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA55.spacy\n",
            "2021-06-30 15:19:48.129189: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA56.spacy\n",
            "2021-06-30 15:20:04.777767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA57.spacy\n",
            "2021-06-30 15:20:21.425098: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA58.spacy\n",
            "2021-06-30 15:20:38.080492: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA59.spacy\n",
            "2021-06-30 15:20:54.804729: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA60.spacy\n",
            "2021-06-30 15:21:11.509958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA61.spacy\n",
            "2021-06-30 15:21:29.200567: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA62.spacy\n",
            "2021-06-30 15:21:45.862681: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA63.spacy\n",
            "2021-06-30 15:22:02.466677: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA64.spacy\n",
            "2021-06-30 15:22:19.240396: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA65.spacy\n",
            "2021-06-30 15:22:36.100466: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA66.spacy\n",
            "2021-06-30 15:22:52.685360: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA67.spacy\n",
            "2021-06-30 15:23:09.278694: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA68.spacy\n",
            "2021-06-30 15:23:25.908560: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA69.spacy\n",
            "2021-06-30 15:23:42.445262: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA70.spacy\n",
            "2021-06-30 15:23:58.912293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA71.spacy\n",
            "2021-06-30 15:24:15.340270: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA72.spacy\n",
            "2021-06-30 15:24:32.180060: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA73.spacy\n",
            "2021-06-30 15:24:48.975906: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description lofi pop key with too loud and too loud dm me for dry stems and custom loops also link me songs' and words '[]'.\n",
            "2021-06-30 15:24:59.090540: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA75.spacy\n",
            "2021-06-30 15:25:15.578722: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA76.spacy\n",
            "2021-06-30 15:25:38.230349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA77.spacy\n",
            "2021-06-30 15:25:55.200012: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA78.spacy\n",
            "2021-06-30 15:26:12.064269: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA79.spacy\n",
            "2021-06-30 15:26:28.787932: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description slap-back sine bells made with logic stock show me what you make' and words '[]'.\n",
            "2021-06-30 15:26:37.013642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA81.spacy\n",
            "2021-06-30 15:26:53.701767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA82.spacy\n",
            "2021-06-30 15:27:10.357976: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA83.spacy\n",
            "2021-06-30 15:27:27.051148: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA84.spacy\n",
            "2021-06-30 15:27:43.824746: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA85.spacy\n",
            "2021-06-30 15:28:00.455861: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA86.spacy\n",
            "2021-06-30 15:28:17.172991: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA87.spacy\n",
            "2021-06-30 15:28:33.867899: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA88.spacy\n",
            "2021-06-30 15:28:50.639605: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA89.spacy\n",
            "2021-06-30 15:29:07.380512: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Traceback (most recent call last):\n",
            "  File \"scripts/preprocess.py\", line 31, in <module>\n",
            "    typer.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 859, in run\n",
            "    app()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 214, in __call__\n",
            "    return get_command(self)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 497, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"scripts/preprocess.py\", line 19, in main\n",
            "    words, spaces = get_words_and_spaces(tokens, eg[\"text\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1231, in get_words_and_spaces\n",
            "    raise ValueError(Errors.E194.format(text=text, words=words))\n",
            "ValueError: [E194] Unable to aligned mismatched text 'description piano viybe light' and words '[]'.\n",
            "2021-06-30 15:29:20.213925: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA91.spacy\n",
            "2021-06-30 15:29:37.488643: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA92.spacy\n",
            "2021-06-30 15:29:54.285054: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA93.spacy\n",
            "2021-06-30 15:30:11.351027: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA94.spacy\n",
            "2021-06-30 15:30:28.055582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA95.spacy\n",
            "2021-06-30 15:30:44.828151: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA96.spacy\n",
            "2021-06-30 15:31:01.369280: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA97.spacy\n",
            "2021-06-30 15:31:17.936848: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA98.spacy\n",
            "2021-06-30 15:31:34.491695: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 19852 documents: TRAIN_DATA99.spacy\n",
            "2021-06-30 15:31:51.185868: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Processed 21 documents: TRAIN_DATA100.spacy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GUnSa7omEay"
      },
      "source": [
        "!zip -r /corpus.zip /content/corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lBf5MoxOC3D"
      },
      "source": [
        "# !python -m spacy project run preprocess\n",
        "!python scripts/preprocess.py merged_file_quarter.jsonl corpus/TRAIN_ALL_QUARTER.spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xds9LuitNqch"
      },
      "source": [
        "## Check the config file\n",
        "\n",
        "* Cannot check properly with large dataset because of memory issues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVrMv3h_NgNa"
      },
      "source": [
        "!python -m spacy debug data configs/config.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG9jpo3BOOmY"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcH0mZT5OQ_K"
      },
      "source": [
        "# !python -m spacy project run train\n",
        "!python -m spacy train configs/config.cfg --output training/ --paths.train corpus/TEST_CONTEXT.spacy --paths.dev corpus/TEST_CONTENT.spacy --gpu-id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmWXqLUqCWjv"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8_FVJOfCQRx"
      },
      "source": [
        "# !python -m spacy project run evaluate\n",
        "!python -m spacy evaluate training/model-best corpus/fashion_brands_eval.spacy --output training/metrics.json --gpu-id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uYBIJwt5pl2"
      },
      "source": [
        "## Archive the generated model/data/images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyDleMAd8qnS"
      },
      "source": [
        "# !unzip /content/data.zip\n",
        "# !unzip /content/saved_model.zip\n",
        "# !zip -r /content/data.zip /content/data\n",
        "# !zip -r /content/img.zip /content/img\n",
        "# !zip -r /content/saved_model.zip /content/saved_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}