{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spaCy_NER_Eval_Config.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dYR2u9U0_JLB",
        "rZDk28NRC_s8"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQUUODx7h4v"
      },
      "source": [
        "# NER Evaluation of Augmented data\n",
        "\n",
        "* This evaluation is done in Google Colab because of:\n",
        "    * Enormous dataset size\n",
        "    * Transformer based architecture involving GPU usage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYR2u9U0_JLB"
      },
      "source": [
        "## Install spaCy and download English model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRBO4JulnpP7"
      },
      "source": [
        "# !pip install cupy-cuda112\n",
        "!pip install spacy==3.0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaJC5o7XpHOs"
      },
      "source": [
        "# Download spacy small model\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0JtYDT_Dx7S"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBp28TAJmhB"
      },
      "source": [
        "## Install torch\n",
        "\n",
        "* Install torch specifc to the Google Colab's CUDA version\n",
        "* CUDA version 11.1 works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LAGZmbvE0VQ"
      },
      "source": [
        "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WzjtepqIlx2"
      },
      "source": [
        "## Extract Project files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd4cI8yUIscq"
      },
      "source": [
        "!unzip /content/project.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZDk28NRC_s8"
      },
      "source": [
        "## Pre-process and save to json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyNJ16vJ5Xov"
      },
      "source": [
        "### Extract the augmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wph-DdQFKPnO"
      },
      "source": [
        "!unzip /content/augmented_dataset_2021-06-21.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qCBw9tx5f9R"
      },
      "source": [
        "### Loader function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDjtHcwhDMYD"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import numpy\n",
        "from numpy.core.defchararray import find\n",
        "\n",
        "TRAIN_DATA_PATH = \"./augmented_dataset_2021-06-21/train.csv\"\n",
        "TEST_CONTENT_DATA_PATH = \"./augmented_dataset_2021-06-21/test_content.csv\"\n",
        "TEST_CONTEXT_DATA_PATH = \"./augmented_dataset_2021-06-21/test_context.csv\"\n",
        "TEST_UNSEEN = \"./augmented_dataset_2021-06-21/test_unseen.csv\"\n",
        "\n",
        "def load_cleaned_data(data_path, train_data_only=None):\n",
        "    \"\"\"\n",
        "    Go through every sentence's all word-tag pair (except \"NONE\")\n",
        "    and calculate the start and end index.\n",
        "    After getting the (start, end) pair, check if this pair was already calculated\n",
        "    (i.e., either the start_index, OR end_index, OR both are matching with the ones in list),\n",
        "    and if so, discard the pair and continue calculating again, skipping over the one discarded.\n",
        "    :return: DATA\n",
        "    \"\"\"\n",
        "    if train_data_only is not None:\n",
        "        col_names = ['text', 'entities']\n",
        "\n",
        "        data = pd.read_csv(data_path, names=col_names, usecols=[0, 1])\n",
        "        entity_list = data.entities.to_list()\n",
        "\n",
        "    else:\n",
        "        # Incoming `train_data_only` is itself a pandas,\n",
        "        # so just process it.\n",
        "        entity_list = data.entities.to_list()\n",
        "\n",
        "    DATA = []\n",
        "\n",
        "    for index, ent in enumerate(entity_list):\n",
        "        if ent == \"tokens\":\n",
        "            continue\n",
        "\n",
        "        ent = ent.split(\"), (\")\n",
        "        ent[0] = re.sub(\"[([]\", \"\", ent[0])\n",
        "        ent[-1] = re.sub(\"[)]]\", \"\", ent[-1])\n",
        "\n",
        "        # Initialize index list, to store pairs of (start, end) indices\n",
        "        indices_list = [(-1, -1), (-1, -1)]\n",
        "\n",
        "        tokens_list = []\n",
        "        spans_list = []\n",
        "\n",
        "        start_index = 0\n",
        "        end_index = 0\n",
        "\n",
        "        # Analyze current \"split_sentences\"'s all word-pairs\n",
        "        for index_ent, word_pair in enumerate(ent):\n",
        "            # Split the word and its pair\n",
        "            word_pair_list = word_pair.split(\"'\")[1::2]\n",
        "\n",
        "            # Remove any leading or beginning blank space\n",
        "            word_pair_list[0] = word_pair_list[0].strip()\n",
        "\n",
        "            start_index = find(data['text'][index].lower(), word_pair_list[0]).astype(numpy.int64)\n",
        "            start_index = int(start_index + 0)\n",
        "            end_index = int(start_index + len(word_pair_list[0]))\n",
        "\n",
        "            # Incase word not found in the sentence\n",
        "            if start_index == -1:\n",
        "                print(\"-1 error\")\n",
        "                print(data['text'][index])\n",
        "                break\n",
        "\n",
        "            both_present = lambda: (start_index, end_index) in indices_list\n",
        "            start_present = lambda: start_index in [i[0] for i in indices_list]\n",
        "            end_present = lambda: end_index in [i[1] for i in indices_list]\n",
        "            left_blank = lambda: data['text'][index][start_index - 1] != \" \"\n",
        "\n",
        "            def right_blank():\n",
        "                # return true if there is no blank space after the end_index,\n",
        "                # as long as end_index is not at the end of the sentence\n",
        "                if len(data['text'][index].lower()) != end_index:\n",
        "                    return data['text'][index][end_index] != \" \"\n",
        "            \n",
        "            # Check if this start_index and/or end_index is already in the list:\n",
        "            # (To prevent overlapping with already tagged words)\n",
        "            flag = 0\n",
        "            while True:\n",
        "                if (start_index == -1 or end_index == -1):\n",
        "                    flag = 1\n",
        "                    break\n",
        "                if (both_present()) or (start_present()) or (end_present()) or (left_blank()) or (right_blank()):\n",
        "                \n",
        "                    start_index = find(data['text'][index].lower(), word_pair_list[0],\n",
        "                                        start=end_index + 1).astype(numpy.int64)\n",
        "                    start_index = int(start_index + 0)\n",
        "                    end_index = int(start_index + len(word_pair_list[0]))\n",
        "\n",
        "                else:\n",
        "                    indices_list.append((start_index, end_index))\n",
        "                    break\n",
        "            \n",
        "            if (flag == 1):\n",
        "                # Don't bother checking rest of the current sentence\n",
        "                break\n",
        "            \n",
        "            # Add ALL the words and their positions to a \"tokens\" list\n",
        "            tokens_list.append({\"text\": word_pair_list[0], \"start\": start_index, \"end\": end_index})\n",
        "\n",
        "            # Add the specially tagged words to a \"spans\" list\n",
        "            if word_pair_list[1] != \"NONE\":\n",
        "                spans_list.append({\"start\": start_index, \"end\": end_index, \"label\": word_pair_list[1]})\n",
        "\n",
        "        DATA.append({\"text\": data['text'][index].lower(), \"tokens\": tokens_list, \"spans\": spans_list, \"answer\": \"accept\"})\n",
        "        \n",
        "    return DATA\n",
        "\n",
        "\n",
        "# TRAIN_DATA = load_cleaned_data(TRAIN_DATA_PATH)\n",
        "# TEST_CONTENT = load_cleaned_data(TEST_CONTENT_DATA_PATH)\n",
        "# TEST_CONTEXT = load_cleaned_data(TEST_CONTEXT_DATA_PATH)\n",
        "# UNSEEN_DATA = load_cleaned_data(TEST_UNSEEN)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-W4UdARgRf"
      },
      "source": [
        "### Load and save `TRAIN_DATA` in batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uePVdIfvRfn8",
        "outputId": "0216bb78-88db-4a81-818c-9037d4bf037b"
      },
      "source": [
        "from spacy.util import minibatch\n",
        "\n",
        "# Create assets directory if it doesn't already exist\n",
        "if not os.path.exists(\"assets\"):\n",
        "    os.makedirs(\"assets\")\n",
        "\n",
        "# Calulate size of each of the `div` batches\n",
        "tot_size = 1985221\n",
        "div = 10\n",
        "num_groups = int(tot_size / div)\n",
        "print(f\"Size of each part: {num_groups}\\n\")\n",
        "\n",
        "# Read the CSV file as Pandas df and divide it into batches\n",
        "col_names = ['text', 'entities']\n",
        "data = pd.read_csv(TRAIN_DATA_PATH, names=col_names, usecols=[0, 1])\n",
        "batches = minibatch(data, size=num_groups)\n",
        "\n",
        "# Process each batch one by one, and save its result in a seperate jsonl file\n",
        "for count, batch in enumerate(batches):\n",
        "    TRAIN_DATA = load_cleaned_data(data_path=TRAIN_DATA_PATH,\n",
        "                                   train_data_only=batch)\n",
        "\n",
        "    with open(f\"assets/TRAIN_DATA{count}.jsonl\", 'w') as f:\n",
        "        for entry in TRAIN_DATA:\n",
        "            json.dump(entry, f)\n",
        "            f.write('\\n')\n",
        "\n",
        "    print(f\"Batch {count} procesed and saved.\")\n",
        "    TRAIN_DATA.clear()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of each part: 198522\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaFqxUFg5jTv"
      },
      "source": [
        "### Save to JSONL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QamFbSfcXJT"
      },
      "source": [
        "import json\n",
        "\n",
        "if not os.path.exists(\"assets\"):\n",
        "        os.makedirs(\"assets\")\n",
        "\n",
        "# with open('assets/TRAIN_DATA.jsonl', 'w') as f:\n",
        "#     for entry in TRAIN_DATA:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/TEST_CONTENT.jsonl', 'w') as f:\n",
        "#     for entry in TEST_CONTENT:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/TEST_CONTEXT.jsonl', 'w') as f:\n",
        "#     for entry in TEST_CONTEXT:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n",
        "\n",
        "# with open('assets/UNSEEN_DATA.jsonl', 'w') as f:\n",
        "#     for entry in UNSEEN_DATA:\n",
        "#         json.dump(entry, f)\n",
        "#         f.write('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jza6xEbE5ofN"
      },
      "source": [
        "### Zip the JSONL files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdsTfX-vqBd3"
      },
      "source": [
        "!zip -r /content/assets.zip /content/assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Auxp_oSxUe2u"
      },
      "source": [
        "## Extract assets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQf0WHMtsGCy"
      },
      "source": [
        "!unzip /content/assets.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jvWOqtpN9rT"
      },
      "source": [
        "## Convert the data to spaCy's binary format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lBf5MoxOC3D"
      },
      "source": [
        "!python -m spacy project run preprocess"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xds9LuitNqch"
      },
      "source": [
        "## Check the config file\n",
        "\n",
        "* Cannot check properly with large dataset because of memory issues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVrMv3h_NgNa"
      },
      "source": [
        "!python -m spacy debug data configs/config.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG9jpo3BOOmY"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcH0mZT5OQ_K"
      },
      "source": [
        "# !python -m spacy project run train\n",
        "!python -m spacy train configs/config.cfg --output training/ --paths.train corpus/TEST_CONTEXT.spacy --paths.dev corpus/TEST_CONTENT.spacy --gpu-id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmWXqLUqCWjv"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8_FVJOfCQRx"
      },
      "source": [
        "# !python -m spacy project run evaluate\n",
        "!python -m spacy evaluate training/model-best corpus/fashion_brands_eval.spacy --output training/metrics.json --gpu-id 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uYBIJwt5pl2"
      },
      "source": [
        "## Archive the generated model/data/images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyDleMAd8qnS"
      },
      "source": [
        "# !unzip /content/data.zip\n",
        "# !unzip /content/saved_model.zip\n",
        "# !zip -r /content/data.zip /content/data\n",
        "# !zip -r /content/img.zip /content/img\n",
        "# !zip -r /content/saved_model.zip /content/saved_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}