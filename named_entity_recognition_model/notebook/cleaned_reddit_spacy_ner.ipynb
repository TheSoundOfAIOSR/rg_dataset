{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cleaned_reddit_spacy_ner.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "Aox8lnj2k5k_"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zTgDnJZJPqH"
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rQf7NX6eo-Ae"
   },
   "source": [
    "import spacy\n",
    "\n",
    "print(\"spaCy version: \", spacy.__version__)\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed(0)"
   ],
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy version:  3.0.6\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDAY1ayuJTnb"
   },
   "source": [
    "### Download and Load Spacy Language Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaJC5o7XpHOs",
    "outputId": "f3201368-9838-4ec6-bc82-dca86f199ce8"
   },
   "source": [
    "#Download spacy small model\n",
    "!python -m spacy download en_core_web_sm\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 18:52:51.063488: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-05-18 18:52:51.064232: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\archi\\PycharmProjects\\TSOAI\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (56.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.60.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from catalogue<2.1.0,>=2.0.3->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEJI8H0n6l-U"
   },
   "source": [
    "###Updating NER###"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KibB6xx6rE7P"
   },
   "source": [
    "# Getting the pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")"
   ],
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VlXl51JJk2L"
   },
   "source": [
    "## Load processed (and cleaned) Reddit data\n",
    "\n",
    "* Go through every sentence's all word-tag pair (except \"NONE\") and calculate the start and end index.\n",
    "* After getting the (start, end) pair, check if this pair was already calcualted (i.e., either the start_index, OR end_index, OR both are matching with the ones in list), and if so, discard the pair and continue calculuting again, skipping over the one discarded."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bhAetUWuZm76"
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from numpy.core.defchararray import find\n",
    "\n",
    "col_names = ['text', 'entities']\n",
    "\n",
    "data = pd.read_csv('./processed_data.csv', names=col_names)\n",
    "entity_list = data.entities.to_list()\n",
    "\n",
    "DATA = []\n",
    "\n",
    "for index, ent in enumerate(entity_list):\n",
    "  if(ent==\"split_sentences\"):\n",
    "    continue\n",
    "  \n",
    "  ent = ent.split(\"), (\")\n",
    "  ent[0] = re.sub(\"[([]\", \"\", ent[0])\n",
    "  ent[-1] = re.sub(\"[)]]\", \"\", ent[-1])\n",
    "\n",
    "  # Initilize index list, to store pairs of (start, end) indices\n",
    "  indices_list = [(-1, -1), (-1, -1)]\n",
    "\n",
    "  annot_list = []\n",
    "  start_index = 0\n",
    "  end_index = 0\n",
    "\n",
    "  # Analyze current \"split_sentences\"'s all word-pairs\n",
    "  for index_ent, word_pair in enumerate(ent):\n",
    "    # Split the word and its pair\n",
    "    word_pair_list = word_pair.split(\"'\")[1::2]\n",
    "    if word_pair_list[1]!=\"NONE\":\n",
    "\n",
    "      # Remove any leading or beginning blank space\n",
    "      word_pair_list[0] = word_pair_list[0].strip()\n",
    "\n",
    "      start_index = find(data['text'][index].lower(), word_pair_list[0]).astype(numpy.int64)\n",
    "      start_index = start_index + 0\n",
    "      end_index = start_index + len(word_pair_list[0])\n",
    "\n",
    "      # Doesn't happen, just for a check  \n",
    "      if start_index == -1:\n",
    "        print(\"-1 error\")\n",
    "        print(data['text'][index])\n",
    "        break\n",
    "\n",
    "      # Check if this start_index and/or end_index is already in the list:\n",
    "      # (To prevent overlapping with already tagged words)\n",
    "      while True:\n",
    "        if ((start_index, end_index) in indices_list) or (end_index in [i[1] for i in indices_list]) or (start_index in [i[0] for i in indices_list]):\n",
    "          start_index = find(data['text'][index].lower(), word_pair_list[0], start=end_index+1).astype(numpy.int64)\n",
    "          start_index = start_index + 0\n",
    "          end_index = start_index + len(word_pair_list[0])\n",
    "\n",
    "        else:\n",
    "          indices_list.append((start_index, end_index))\n",
    "          break\n",
    "\n",
    "      annot_list.append((start_index, end_index, word_pair_list[1]))\n",
    "\n",
    "  DATA.append((data['text'][index].lower(), {\"entities\": annot_list}))\n",
    "  # print(indices_list)\n",
    "\n"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ8DaNRxYH1r"
   },
   "source": [
    "Randomly pull out 5 segments for test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kbJQf336hU_",
    "outputId": "80ff215f-b9d8-4043-812a-ac7b3bf7cba3"
   },
   "source": [
    "import random\n",
    "random.shuffle(DATA)\n",
    "\n",
    "# First 5 elements form test data after shuffling\n",
    "TEST_DATA = DATA[:5]\n",
    "\n",
    "for text, annotations in TEST_DATA:\n",
    "  print(text)\n",
    "  print(annotations)\n",
    "\n",
    "TRAIN_DATA = DATA[5:len(DATA)]\n",
    "print(\"\\n\")\n",
    "\n",
    "# for text, annotations in TRAIN_DATA:\n",
    "#   print(text)\n",
    "#   print(annotations)\n",
    "\n",
    "print(\"\\nLength of test data: \", len(TEST_DATA))\n",
    "print(\"Length of train data: \", len(TRAIN_DATA))\n"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar amp sim in addition to my clean bass guitar i compress it really good and in a separate track i add a guitar amp sim on it with some light distortion find a balance that sounds good in the mix and it sounds good enough to take a bite out of\n",
      "{'entities': [(0, 6, 'INSTR'), (33, 38, 'QLTY'), (140, 156, 'QLTY')]}\n",
      "i learned to play folk on a classical about 30 years ago they re different instruments but they do both have the long sticky bit with 6 strings attached a classical neck is wider and flatter so get a classical as soon as you can but no i don t think you re screwed\n",
      "{'entities': [(28, 37, 'INSTR')]}\n",
      "post rock used to be a lot broader described bands with quite different sounds like slint tortoise or talk talk feels like now it is more narrow bands tend to sound like eits clones with that chiming guitar sound and big crescendos\n",
      "{'entities': [(192, 199, 'QLTY'), (200, 206, 'INSTR'), (217, 231, 'QLTY')]}\n",
      "the amount to which different pitches are present is different for instance i think clarinets only have two frequencies that are majorly present when you play a note a saxophone may have four that is you 2019re not just playing purely a4 with an a4 configuration you may have a5 or a6 or a3 to different amounts according to different instruments the mixture of the different frequencies combined with other factors such as the medium to which the sound travels wood or string or air or brass and amplitude of each frequency results in what we perceive as different timbre there 2019s an amazing lecture by walter lewin on musical instruments that demonstrates this\n",
      "{'entities': [(84, 93, 'INSTR'), (168, 177, 'INSTR')]}\n",
      "as a guitarist who often plays jazz i agree with you there is a lot of possibilities within the world of clean electric guitar tones the examples you gave are perfect i think metheny s tone is a little more bright and clear more treble or mids i suppose adam rogers has got more of the dark warm bassy thing going on depending on the context i like that warm tone but i think some players let it get a tad too muddy for my tastes anywho the electric guitar by its very nature offers vast timbral possibilities that could be massively useful in that context i imagine it is just a matter of time before we see more of it hopefully the los angeles 8 are a guitar ensemble that plays electric guitars here is a video of them playing the third movement of steve reich s electric counterpoint i get the impression that they are trying to earn the electric guitar some street cred in the realm of concert music the ensemble is different than the context you suggested but it seemed relevant\n",
      "{'entities': [(207, 213, 'QLTY'), (218, 223, 'QLTY'), (286, 290, 'QLTY'), (291, 295, 'QLTY'), (296, 301, 'QLTY'), (681, 697, 'INSTR')]}\n",
      "\n",
      "\n",
      "\n",
      "Length of test data:  5\n",
      "Length of train data:  176\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PK71RupWQnZ"
   },
   "source": [
    "## Adding labels to the `ner`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LqjxlFOMCxiq"
   },
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])"
   ],
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53jmOHKWWgpO"
   },
   "source": [
    "### Disable pipeline components that is not changed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Phkm8ugvWVdd"
   },
   "source": [
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ],
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WMAnYtSXknr"
   },
   "source": [
    "### Train NER"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DnkTk5EkWvw6"
   },
   "source": [
    "# Import requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "# from pathlib import Path\n",
    "\n",
    "ITERATIONS = 50\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "    # Create a list of Examples objects\n",
    "    examples = []\n",
    "    for text, annots in TRAIN_DATA:\n",
    "        examples.append(Example.from_dict(nlp.make_doc(text), annots))\n",
    "\n",
    "    for iteration in range(ITERATIONS):\n",
    "        # print(\"Iteration: \", iteration)\n",
    "        # shuffling examples  before every iteration\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(examples, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            \n",
    "            nlp.update(\n",
    "                        batch,\n",
    "                        drop = DROPOUT,  # dropout - make it harder to memorise data\n",
    "                        losses=losses\n",
    "                    )\n",
    "            # print(\"Losses\", losses)"
   ],
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"to my ears this is very loud i can see where you a...\" with entities \"[(191, 197, 'INSTR'), (240, 245, 'INSTR')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"what if rock music didn t emphasize the electric g...\" with entities \"[(49, 55, 'INSTR'), (136, 141, 'INSTR')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"there are definitely affordable classicals my firs...\" with entities \"[(32, 41, 'INSTR'), (62, 68, 'INSTR'), (134, 146, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"this is a point i cannot stress enough move your b...\" with entities \"[(49, 53, 'INSTR')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"just google gut strings classical guitar and you c...\" with entities \"[(13, 40, 'INSTR')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"it depends on the genre depending on the genre giv...\" with entities \"[(68, 72, 'INSTR'), (1278, 1283, 'INSTR'), (3454, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"i don 2019t have the answer to your guitar questio...\" with entities \"[(36, 42, 'INSTR'), (91, 102, 'INSTR'), (124, 135,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n",
      "c:\\users\\archi\\pycharmprojects\\tsoai\\venv\\lib\\site-packages\\spacy\\training\\iob_utils.py:142: UserWarning: [W030] Some entities could not be aligned in the text \"evolving dawless modular jam one note haha really ...\" with entities \"[(0, 8, 'QLTY'), (9, 16, 'QLTY'), (127, 133, 'INST...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  entities=ent_str[:50] + \"...\" if len(ent_str) > 50 else ent_str,\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVi_2w3GJA4Q"
   },
   "source": [
    "### Test on TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWVEyZBlBWUK",
    "outputId": "a1edc928-b975-4dae-a76d-7c0fc6f5c160"
   },
   "source": [
    "for example in TEST_DATA:\n",
    "  print(example[0])\n",
    "  doc = nlp(example[0])\n",
    "  print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar amp sim in addition to my clean bass guitar i compress it really good and in a separate track i add a guitar amp sim on it with some light distortion find a balance that sounds good in the mix and it sounds good enough to take a bite out of\n",
      "Entities [('guitar', 'INSTR'), ('clean', 'QLTY'), ('bass guitar', 'INSTR'), ('distortion', 'QLTY')]\n",
      "i learned to play folk on a classical about 30 years ago they re different instruments but they do both have the long sticky bit with 6 strings attached a classical neck is wider and flatter so get a classical as soon as you can but no i don t think you re screwed\n",
      "Entities []\n",
      "post rock used to be a lot broader described bands with quite different sounds like slint tortoise or talk talk feels like now it is more narrow bands tend to sound like eits clones with that chiming guitar sound and big crescendos\n",
      "Entities [('guitar', 'INSTR')]\n",
      "the amount to which different pitches are present is different for instance i think clarinets only have two frequencies that are majorly present when you play a note a saxophone may have four that is you 2019re not just playing purely a4 with an a4 configuration you may have a5 or a6 or a3 to different amounts according to different instruments the mixture of the different frequencies combined with other factors such as the medium to which the sound travels wood or string or air or brass and amplitude of each frequency results in what we perceive as different timbre there 2019s an amazing lecture by walter lewin on musical instruments that demonstrates this\n",
      "Entities []\n",
      "as a guitarist who often plays jazz i agree with you there is a lot of possibilities within the world of clean electric guitar tones the examples you gave are perfect i think metheny s tone is a little more bright and clear more treble or mids i suppose adam rogers has got more of the dark warm bassy thing going on depending on the context i like that warm tone but i think some players let it get a tad too muddy for my tastes anywho the electric guitar by its very nature offers vast timbral possibilities that could be massively useful in that context i imagine it is just a matter of time before we see more of it hopefully the los angeles 8 are a guitar ensemble that plays electric guitars here is a video of them playing the third movement of steve reich s electric counterpoint i get the impression that they are trying to earn the electric guitar some street cred in the realm of concert music the ensemble is different than the context you suggested but it seemed relevant\n",
      "Entities [('clean', 'QLTY'), ('electric guitar', 'INSTR'), ('dark', 'QLTY'), ('electric guitar', 'INSTR'), ('electric guitars', 'INSTR'), ('electric guitar', 'INSTR')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWZ-srQVJFD_"
   },
   "source": [
    "### Print original TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAHYimYuNYJl",
    "outputId": "11f8eb5a-fbd1-45f2-8047-5f42ebdb44c2"
   },
   "source": [
    "for text, annotations in TEST_DATA:\n",
    "  print(text)\n",
    "  print(annotations)"
   ],
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guitar amp sim in addition to my clean bass guitar i compress it really good and in a separate track i add a guitar amp sim on it with some light distortion find a balance that sounds good in the mix and it sounds good enough to take a bite out of\n",
      "{'entities': [(0, 6, 'INSTR'), (33, 38, 'QLTY'), (140, 156, 'QLTY')]}\n",
      "i learned to play folk on a classical about 30 years ago they re different instruments but they do both have the long sticky bit with 6 strings attached a classical neck is wider and flatter so get a classical as soon as you can but no i don t think you re screwed\n",
      "{'entities': [(28, 37, 'INSTR')]}\n",
      "post rock used to be a lot broader described bands with quite different sounds like slint tortoise or talk talk feels like now it is more narrow bands tend to sound like eits clones with that chiming guitar sound and big crescendos\n",
      "{'entities': [(192, 199, 'QLTY'), (200, 206, 'INSTR'), (217, 231, 'QLTY')]}\n",
      "the amount to which different pitches are present is different for instance i think clarinets only have two frequencies that are majorly present when you play a note a saxophone may have four that is you 2019re not just playing purely a4 with an a4 configuration you may have a5 or a6 or a3 to different amounts according to different instruments the mixture of the different frequencies combined with other factors such as the medium to which the sound travels wood or string or air or brass and amplitude of each frequency results in what we perceive as different timbre there 2019s an amazing lecture by walter lewin on musical instruments that demonstrates this\n",
      "{'entities': [(84, 93, 'INSTR'), (168, 177, 'INSTR')]}\n",
      "as a guitarist who often plays jazz i agree with you there is a lot of possibilities within the world of clean electric guitar tones the examples you gave are perfect i think metheny s tone is a little more bright and clear more treble or mids i suppose adam rogers has got more of the dark warm bassy thing going on depending on the context i like that warm tone but i think some players let it get a tad too muddy for my tastes anywho the electric guitar by its very nature offers vast timbral possibilities that could be massively useful in that context i imagine it is just a matter of time before we see more of it hopefully the los angeles 8 are a guitar ensemble that plays electric guitars here is a video of them playing the third movement of steve reich s electric counterpoint i get the impression that they are trying to earn the electric guitar some street cred in the realm of concert music the ensemble is different than the context you suggested but it seemed relevant\n",
      "{'entities': [(207, 213, 'QLTY'), (218, 223, 'QLTY'), (286, 290, 'QLTY'), (291, 295, 'QLTY'), (296, 301, 'QLTY'), (681, 697, 'INSTR')]}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR88U92mJL1f"
   },
   "source": [
    "### Extracting Entities\n",
    "(Not used)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIWEl15-0-7S",
    "outputId": "f611d000-fa94-44ec-ebbe-848cf3db51c1"
   },
   "source": [
    "for text, annotations in TEST_DATA:\n",
    "  print(list(annotations.values()))"
   ],
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 6, 'INSTR'), (33, 38, 'QLTY'), (140, 156, 'QLTY')]]\n",
      "[[(28, 37, 'INSTR')]]\n",
      "[[(192, 199, 'QLTY'), (200, 206, 'INSTR'), (217, 231, 'QLTY')]]\n",
      "[[(84, 93, 'INSTR'), (168, 177, 'INSTR')]]\n",
      "[[(207, 213, 'QLTY'), (218, 223, 'QLTY'), (286, 290, 'QLTY'), (291, 295, 'QLTY'), (296, 301, 'QLTY'), (681, 697, 'INSTR')]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXasNID87K3x",
    "outputId": "72d69056-99eb-455c-c9e0-a212c7eeb06d"
   },
   "source": [
    "for ent_iterator in range(len(TEST_DATA)):\n",
    "  print(list(*TEST_DATA[ent_iterator][1].values()))"
   ],
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 6, 'INSTR'), (33, 38, 'QLTY'), (140, 156, 'QLTY')]\n",
      "[(28, 37, 'INSTR')]\n",
      "[(192, 199, 'QLTY'), (200, 206, 'INSTR'), (217, 231, 'QLTY')]\n",
      "[(84, 93, 'INSTR'), (168, 177, 'INSTR')]\n",
      "[(207, 213, 'QLTY'), (218, 223, 'QLTY'), (286, 290, 'QLTY'), (291, 295, 'QLTY'), (296, 301, 'QLTY'), (681, 697, 'INSTR')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fo4LY9E96c28",
    "outputId": "fe21c258-d654-499c-ca71-9eefa7614732"
   },
   "source": [
    "TEST_DATA[0][1]"
   ],
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "{'entities': [(0, 6, 'INSTR'), (33, 38, 'QLTY'), (140, 156, 'QLTY')]}"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCbFknpKJUQ1"
   },
   "source": [
    "### Evaluate scores on TEST_DATA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1UTJrKoG9law",
    "outputId": "9f055fa5-4c18-4c73-da00-537cef245243"
   },
   "source": [
    "# from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "scorer = Scorer()\n",
    "example_list = []\n",
    "\n",
    "for text, annot in TEST_DATA:\n",
    "  # Create a Doc of our text\n",
    "  doc_gold_text = nlp.make_doc(text)\n",
    "\n",
    "  # Create gold-standard using the Doc of text\n",
    "  # and original (correct) entities\n",
    "\n",
    "  # v2.x style:\n",
    "  # gold = GoldParse(doc_gold_text, entities=annot['entities'])\n",
    "\n",
    "  # v3.x style:\n",
    "  # example = Example.from_dict(doc_gold_text, {\"entities\": annot[\"entities\"]})\n",
    "\n",
    "  pred_value = nlp(text)\n",
    "  reference = (Example.from_dict(doc_gold_text, annot))\n",
    "  gold_standard = {\"text\": doc_gold_text, \"entities\": annot[\"entities\"]}\n",
    "\n",
    "  example_list.append(Example.from_dict(pred_value, gold_standard))\n",
    "\n",
    "# Generate per-entity scores by comparing predicted with gold-standard values\n",
    "scores = scorer.score(examples=example_list)\n",
    "\n",
    "print(\"All scores: \", scores)\n",
    "\n",
    "print(\"\\nents_p (aka Precision): \", scores['ents_p'])\n",
    "print(\"ents_r (aka Recall): \", scores['ents_r'])\n",
    "print(\"ents_f (aka fscore): \", scores['ents_f'])\n",
    "\n",
    "print(\"\\nINSTR: \", scores['ents_per_type']['INSTR'])\n",
    "print(\"QLTY: \", scores['ents_per_type']['QLTY'])"
   ],
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All scores:  {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': None, 'sents_r': None, 'sents_f': None, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 0.45454545454545453, 'ents_r': 0.3333333333333333, 'ents_f': 0.3846153846153846, 'ents_per_type': {'INSTR': {'p': 0.42857142857142855, 'r': 0.5, 'f': 0.4615384615384615}, 'QLTY': {'p': 0.5, 'r': 0.2222222222222222, 'f': 0.30769230769230765}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n",
      "\n",
      "ents_p (aka Precision):  0.45454545454545453\n",
      "ents_r (aka Recall):  0.3333333333333333\n",
      "ents_f (aka fscore):  0.3846153846153846\n",
      "\n",
      "INSTR:  {'p': 0.42857142857142855, 'r': 0.5, 'f': 0.4615384615384615}\n",
      "QLTY:  {'p': 0.5, 'r': 0.2222222222222222, 'f': 0.30769230769230765}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvLaWXhB59BW"
   },
   "source": [
    "### Calculate ROC-AUC\n",
    "\n",
    "`scorer.score_cats()` requires spaCy v3 :(\n",
    "\n",
    "TODO: Fix ROC-AUC outputs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "M0zDsD9G58Uq",
    "outputId": "007bf58e-42d0-4158-e187-ab47da56ad79"
   },
   "source": [
    "labels = [\"QLTY\", \"INSTR\"]\n",
    "\n",
    "# for example in TEST_DATA:\n",
    "cat_scores = scorer.score_cats(example_list, attr=\"cats\", labels=labels)\n",
    "# print(cat_scores)\n",
    "for key, cat in cat_scores.items():\n",
    "    print(key)\n",
    "    if isinstance(cat, float) or isinstance(cat, str):\n",
    "        print(\"\\t\", cat)\n",
    "    else:\n",
    "        for attribute, value in cat.items():\n",
    "            print('\\t{} : {}'.format(attribute, value))"
   ],
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats_score\n",
      "\t 0.0\n",
      "cats_score_desc\n",
      "\t macro AUC\n",
      "cats_micro_p\n",
      "\t 0.0\n",
      "cats_micro_r\n",
      "\t 0.0\n",
      "cats_micro_f\n",
      "\t 0.0\n",
      "cats_macro_p\n",
      "\t 0.0\n",
      "cats_macro_r\n",
      "\t 0.0\n",
      "cats_macro_f\n",
      "\t 0.0\n",
      "cats_macro_auc\n",
      "\t 0.0\n",
      "cats_f_per_type\n",
      "\tQLTY : {'p': 0.0, 'r': 0.0, 'f': 0.0}\n",
      "\tINSTR : {'p': 0.0, 'r': 0.0, 'f': 0.0}\n",
      "cats_auc_per_type\n",
      "\tQLTY : None\n",
      "\tINSTR : None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFG0w6IMpHLa"
   },
   "source": [
    "## Test on custom unseen data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRfGX_40BWUL",
    "outputId": "d92d1b9d-5372-496a-bfc6-757ebe320b82"
   },
   "source": [
    "doc = nlp(\"Play me a guitar, and it shouldn't be distorted.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "doc = nlp(\"Give me a sharp cello.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "doc = nlp(\"I used to play guitar, now I play violin and it has some kind of distortion.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ],
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('distorted', 'QLTY')]\n",
      "Entities []\n",
      "Entities [('violin', 'INSTR'), ('distortion', 'QLTY')]\n"
     ]
    }
   ]
  }
 ]
}