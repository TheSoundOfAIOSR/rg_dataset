{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zTgDnJZJPqH"
   },
   "source": [
    "###Import Libraries###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "rQf7NX6eo-Ae"
   },
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "\n",
    "spacy.__version__\n",
    "\n",
    "import numpy\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDAY1ayuJTnb"
   },
   "source": [
    "###Download and Load Spacy Language Model###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaJC5o7XpHOs",
    "outputId": "b675d6d3-583c-4324-f325-eef4b427d331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#Download spacy small model\n",
    "!python -m spacy download en_core_web_sm\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEJI8H0n6l-U"
   },
   "source": [
    "###Updating NER###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "KibB6xx6rE7P"
   },
   "outputs": [],
   "source": [
    "# Getting the pipeline component\n",
    "ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VlXl51JJk2L"
   },
   "source": [
    "## Load processed (and cleaned) Reddit data\n",
    "\n",
    "* Go through every sentence's all word-tag pair (except \"NONE\") and calculate the start and end index.\n",
    "* After getting the (start, end) pair, check if this pair was already calcualted (i.e., either the start_index, OR end_index, OR both are matching with the ones in list), and if so, discard the pair and continue calculuting again, skipping over the one discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "bhAetUWuZm76"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from numpy.core.defchararray import find\n",
    "\n",
    "col_names = ['text', 'entities']\n",
    "\n",
    "data = pd.read_csv('./processed_data.csv', names=col_names)\n",
    "entity_list = data.entities.to_list()\n",
    "\n",
    "DATA = []\n",
    "\n",
    "for index, ent in enumerate(entity_list):\n",
    "  if(ent==\"split_sentences\"):\n",
    "    continue\n",
    "  \n",
    "  ent = ent.split(\"), (\")\n",
    "  ent[0] = re.sub(\"[([]\", \"\", ent[0])\n",
    "  ent[-1] = re.sub(\"[)]]\", \"\", ent[-1])\n",
    "\n",
    "  # Initilize index list, to store pairs of (start, end) indices\n",
    "  indices_list = [(-1, -1), (-1, -1)]\n",
    "\n",
    "  annot_list = []\n",
    "  start_index = 0\n",
    "  end_index = 0\n",
    "\n",
    "  # Analyze current \"split_sentences\"'s all word-pairs\n",
    "  for index_ent, word_pair in enumerate(ent):\n",
    "    # Split the word and its pair\n",
    "    word_pair_list = word_pair.split(\"'\")[1::2]\n",
    "    if word_pair_list[1]!=\"NONE\":\n",
    "\n",
    "      # Remove any leading or beginning blank space\n",
    "      word_pair_list[0] = word_pair_list[0].strip()\n",
    "\n",
    "      start_index = find(data['text'][index].lower(), word_pair_list[0]).astype(numpy.int64)\n",
    "      start_index = start_index + 0\n",
    "      end_index = start_index + len(word_pair_list[0])\n",
    "\n",
    "      # Doesn't happen, just for a check  \n",
    "      if start_index == -1:\n",
    "        print(\"-1 error\")\n",
    "        print(data['text'][index])\n",
    "        break\n",
    "\n",
    "      # Check if this start_index and/or end_index is already in the list:\n",
    "      # (To prevent overlapping with already tagged words)\n",
    "      while True:\n",
    "        if ((start_index, end_index) in indices_list) or (end_index in [i[1] for i in indices_list]) or (start_index in [i[0] for i in indices_list]):\n",
    "          start_index = find(data['text'][index].lower(), word_pair_list[0], start=end_index+1).astype(numpy.int64)\n",
    "          start_index = start_index + 0\n",
    "          end_index = start_index + len(word_pair_list[0])\n",
    "\n",
    "        else:\n",
    "          indices_list.append((start_index, end_index))\n",
    "          break\n",
    "\n",
    "      annot_list.append((start_index, end_index, word_pair_list[1]))\n",
    "\n",
    "  DATA.append((data['text'][index].lower(), {\"entities\": annot_list}))\n",
    "  # print(indices_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQ8DaNRxYH1r"
   },
   "source": [
    "Randomly pull out 5 segments for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2kbJQf336hU_",
    "outputId": "ce2c6a8f-7a32-4a60-9dfc-30cab9704a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes it 2019s just easier in given situations to hit a note on a different string like if you 2019re doing a pattern that you would have to break if you wanted to go to the next string maybe i don 2019t know not a guitar player other than basic chords there 2019s just options and in given situations some are easier and some are more difficult\n",
      "{'entities': [(219, 225, 'INSTR')]}\n",
      "electric guitar neck pick up bass set to 11\n",
      "{'entities': [(0, 15, 'INSTR'), (29, 33, 'INSTR')]}\n",
      "example the composition that i am trying to write would really benifit from a thick bass\n",
      "{'entities': [(78, 83, 'QLTY'), (84, 88, 'INSTR')]}\n",
      "dubstep drops like the ones au5 and virtual riot create are far more heavily focused on rhythm and sound design than traditional music theory they are absolutely writing in a different way than you re used to it s the groove that s most important dubstep producers almost always start with a drum pattern and a bass line anything else is just icing on the cake clean sounding drops are all about clear separation between frequencies and phrases and forget dynamics modern dubstep covets loudness above all else that said it s still possible to have heavy dubstep drops that are based on progressions as you re used to writing them just listen to some of kai wachi or sullivan king s stuff\n",
      "{'entities': [(549, 554, 'QLTY')]}\n",
      "i was also a guitar player who transitioned into making edm and like you i would always start out writing songs the same way as you with chord progressions and melodies i understand your struggle and what i ve done that really helps when writing drops is to write a simple piano melody and then create bass sounds that follow the same notes and rhythm as your piano melody the key here is to keep the melody simpler than you would if it was being played by a melodic instrument the sound design will fill in the gaps and make your simple not that interesting melody sound great in context of the song also utilize a click track which contains the rhythm you want the drop to follow after laying everything out mute your piano melody and click track and boom you have a drop at this point you can adjust your track to fit around your drums or vice versa\n",
      "{'entities': [(273, 278, 'INSTR'), (302, 306, 'INSTR'), (833, 838, 'INSTR')]}\n",
      "\n",
      "\n",
      "\n",
      "Length of test data:  5\n",
      "Length of train data:  176\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(DATA)\n",
    "\n",
    "# First 5 elements form test data after shuffling\n",
    "TEST_DATA = DATA[:5]\n",
    "\n",
    "for text, annotations in TEST_DATA:\n",
    "  print(text)\n",
    "  print(annotations)\n",
    "\n",
    "TRAIN_DATA = DATA[5:len(DATA)]\n",
    "print(\"\\n\")\n",
    "\n",
    "# for text, annotations in TRAIN_DATA:\n",
    "#   print(text)\n",
    "#   print(annotations)\n",
    "\n",
    "print(\"\\nLength of test data: \", len(TEST_DATA))\n",
    "print(\"Length of train data: \", len(TRAIN_DATA))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PK71RupWQnZ"
   },
   "source": [
    "## Adding labels to the `ner`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "LqjxlFOMCxiq"
   },
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53jmOHKWWgpO"
   },
   "source": [
    "###Disable pipeline components that is not changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Phkm8ugvWVdd"
   },
   "outputs": [],
   "source": [
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WMAnYtSXknr"
   },
   "source": [
    "###Train NER###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "DnkTk5EkWvw6"
   },
   "outputs": [],
   "source": [
    "# Import requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "ITERATIONS = 64\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# TRAINING THE MODEL\n",
    "with nlp.disable_pipes(*unaffected_pipes):\n",
    "  for iteration in range(ITERATIONS):\n",
    "    # print(\"Iteration: \", iteration)\n",
    "    # shuufling examples  before every iteration\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        \n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    drop = DROPOUT,  # dropout - make it harder to memorise data\n",
    "                    losses=losses\n",
    "                )\n",
    "        # print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWVEyZBlBWUK",
    "outputId": "8565c73e-e4b4-4e2b-c046-1e826661ce68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes it 2019s just easier in given situations to hit a note on a different string like if you 2019re doing a pattern that you would have to break if you wanted to go to the next string maybe i don 2019t know not a guitar player other than basic chords there 2019s just options and in given situations some are easier and some are more difficult\n",
      "Entities [('guitar', 'INSTR')]\n",
      "electric guitar neck pick up bass set to 11\n",
      "Entities [('electric guitar', 'INSTR'), ('bass', 'INSTR')]\n",
      "example the composition that i am trying to write would really benifit from a thick bass\n",
      "Entities [('thick bass', 'INSTR')]\n",
      "dubstep drops like the ones au5 and virtual riot create are far more heavily focused on rhythm and sound design than traditional music theory they are absolutely writing in a different way than you re used to it s the groove that s most important dubstep producers almost always start with a drum pattern and a bass line anything else is just icing on the cake clean sounding drops are all about clear separation between frequencies and phrases and forget dynamics modern dubstep covets loudness above all else that said it s still possible to have heavy dubstep drops that are based on progressions as you re used to writing them just listen to some of kai wachi or sullivan king s stuff\n",
      "Entities [('drum', 'INSTR'), ('bass', 'INSTR'), ('clean', 'QLTY')]\n",
      "i was also a guitar player who transitioned into making edm and like you i would always start out writing songs the same way as you with chord progressions and melodies i understand your struggle and what i ve done that really helps when writing drops is to write a simple piano melody and then create bass sounds that follow the same notes and rhythm as your piano melody the key here is to keep the melody simpler than you would if it was being played by a melodic instrument the sound design will fill in the gaps and make your simple not that interesting melody sound great in context of the song also utilize a click track which contains the rhythm you want the drop to follow after laying everything out mute your piano melody and click track and boom you have a drop at this point you can adjust your track to fit around your drums or vice versa\n",
      "Entities [('guitar', 'INSTR')]\n"
     ]
    }
   ],
   "source": [
    "for example in TEST_DATA:\n",
    "  print(example[0])\n",
    "  doc = nlp(example[0])\n",
    "  print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAHYimYuNYJl",
    "outputId": "edc362f2-058f-47ad-d4df-b04ad1e235d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes it 2019s just easier in given situations to hit a note on a different string like if you 2019re doing a pattern that you would have to break if you wanted to go to the next string maybe i don 2019t know not a guitar player other than basic chords there 2019s just options and in given situations some are easier and some are more difficult\n",
      "{'entities': [(219, 225, 'INSTR')]}\n",
      "electric guitar neck pick up bass set to 11\n",
      "{'entities': [(0, 15, 'INSTR'), (29, 33, 'INSTR')]}\n",
      "example the composition that i am trying to write would really benifit from a thick bass\n",
      "{'entities': [(78, 83, 'QLTY'), (84, 88, 'INSTR')]}\n",
      "dubstep drops like the ones au5 and virtual riot create are far more heavily focused on rhythm and sound design than traditional music theory they are absolutely writing in a different way than you re used to it s the groove that s most important dubstep producers almost always start with a drum pattern and a bass line anything else is just icing on the cake clean sounding drops are all about clear separation between frequencies and phrases and forget dynamics modern dubstep covets loudness above all else that said it s still possible to have heavy dubstep drops that are based on progressions as you re used to writing them just listen to some of kai wachi or sullivan king s stuff\n",
      "{'entities': [(549, 554, 'QLTY')]}\n",
      "i was also a guitar player who transitioned into making edm and like you i would always start out writing songs the same way as you with chord progressions and melodies i understand your struggle and what i ve done that really helps when writing drops is to write a simple piano melody and then create bass sounds that follow the same notes and rhythm as your piano melody the key here is to keep the melody simpler than you would if it was being played by a melodic instrument the sound design will fill in the gaps and make your simple not that interesting melody sound great in context of the song also utilize a click track which contains the rhythm you want the drop to follow after laying everything out mute your piano melody and click track and boom you have a drop at this point you can adjust your track to fit around your drums or vice versa\n",
      "{'entities': [(273, 278, 'INSTR'), (302, 306, 'INSTR'), (833, 838, 'INSTR')]}\n"
     ]
    }
   ],
   "source": [
    "for text, annotations in TEST_DATA:\n",
    "  print(text)\n",
    "  print(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFG0w6IMpHLa"
   },
   "source": [
    "## Test on custom unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRfGX_40BWUL",
    "outputId": "ff6da3f3-b590-4dd6-d9cf-73367314c98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('guitar', 'INSTR'), ('distorted', 'QLTY')]\n",
      "Entities [('sharp cello', 'INSTR')]\n",
      "Entities [('guitar', 'INSTR'), ('violin', 'INSTR'), ('distortion', 'QLTY')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Play me a guitar, and it shouldn't be distorted.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "doc = nlp(\"Give me a sharp cello.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "doc = nlp(\"I used to play guitar, now I play violin and it has some kind of distortion.\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Aox8lnj2k5k_"
   ],
   "name": "cleaned_reddit_spacy_ner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
